# -*- coding: utf-8 -*-
"""xTo10x_Hackathon_April2025.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18-t2ZYiOP0zho2xUR0Ebb-8WONA0t1Ru
"""

#!wget https://github.com/wingsryder/Hackathon-Team26/blob/main/Telcom-Customer-Churn.csv

# Phase 1: Structured Procedural Approach for Telco Churn Dataset

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

"""# Data Preparation"""

# Load dataset
url = 'https://raw.githubusercontent.com/wingsryder/Hackathon-Team26/main/Telcom-Customer-Churn.csv'
df = pd.read_csv(url)
df.head()

type(df)

# Remove customerID
if 'customerID' in df.columns:
    df.drop('customerID', axis=1, inplace=True)

df.head()

# Handling Missing values
df.replace(" ", np.nan, inplace=True)
df.dropna(inplace=True)
df['TotalCharges'] = df['TotalCharges'].astype(float)

# Encode Categorical Columns into binary
binary_cols = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn']
df[binary_cols] = df[binary_cols].apply(lambda x: x.map({'Yes': 1, 'No': 0}))

# Converting other Categorical Columns using one hot encoding
categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

# Split data into train/test
X = df.drop('Churn', axis=1)
y = df['Churn']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Model Training"""

# Train Models
models = {
    'Logistic Regression': LogisticRegression(),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'Gradient Boosting': GradientBoostingClassifier(),
    'SVM': SVC()
}
results = []

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    results.append({
        'Model': name,
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred),
        'Recall': recall_score(y_test, y_pred),
        'F1 Score': f1_score(y_test, y_pred)
    })

"""# Model Evaluation"""

results_df = pd.DataFrame(results)
results_df.sort_values(by='F1 Score', ascending=False)

"""# Hyper-Parameter Tuning"""

# Required libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.linear_model import LogisticRegression

class BaseModel:
    def __init__(self, model, param_grid=None):
        self.model = model
        self.param_grid = param_grid  # ‚úÖ Store param_grid here
        self.best_model = None
        self.grid_search = None

    def fit(self, X_train, y_train):
        self.model.fit(X_train, y_train)
        self.best_model = self.model

    def evaluate(self, X_test, y_test):
        y_pred = self.best_model.predict(X_test)
        return {
            'Accuracy': accuracy_score(y_test, y_pred),
            'Precision': precision_score(y_test, y_pred),
            'Recall': recall_score(y_test, y_pred),
            'F1 Score': f1_score(y_test, y_pred)
        }

    def tune(self, X_train, y_train, cv=5, scoring='f1'):
        if not self.param_grid:
            raise ValueError("Parameter grid is empty. Provide 'param_grid' for tuning.")
        self.grid_search = GridSearchCV(self.model, self.param_grid, cv=cv, scoring=scoring, n_jobs=-1)
        self.grid_search.fit(X_train, y_train)
        self.best_model = self.grid_search.best_estimator_
        return self.grid_search.best_params_

    def predict(self, X):
        return self.best_model.predict(X)

from sklearn.preprocessing import StandardScaler

# Reusable function to load and preprocess data
def load_and_prepare_data(file_path):
    df = pd.read_csv(file_path)

    # Drop unnecessary column
    if 'customerID' in df.columns:
        df.drop('customerID', axis=1, inplace=True)

    # Clean and convert numeric
    df.replace(" ", np.nan, inplace=True)
    df.dropna(inplace=True)
    df['TotalCharges'] = df['TotalCharges'].astype(float)

    # Encode binary columns
    binary_cols = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn']
    df[binary_cols] = df[binary_cols].apply(lambda x: x.map({'Yes': 1, 'No': 0}))

    # One-hot encode categorical columns
    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

    # Split features and target
    X = df.drop('Churn', axis=1)
    y = df['Churn']

    # Standardize features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

    return X_train, X_test, y_train, y_test

# Function successfully defined.
"Data loading function is now modular and reusable."

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC

# Logistic Regression Model subclass
class LogisticRegressionModel(BaseModel):
    def __init__(self):
        model = LogisticRegression(max_iter=1000)
        param_grid = {
            'C': [0.01, 0.1, 1, 10, 100],
            'penalty': ['l2'],
            'solver': ['lbfgs']
        }
        super().__init__(model, param_grid)

# Decision Tree

class DecisionTreeModel(BaseModel):
    def __init__(self):
        model = DecisionTreeClassifier()
        param_grid = {
            'criterion': ['gini', 'entropy'],
            'max_depth': [3, 5, 10, 20, 30, None],
            'min_samples_split': [2, 5, 10]
        }
        super().__init__(model, param_grid)

# Random Forest

class RandomForestModel(BaseModel):
    def __init__(self):
        model = RandomForestClassifier()
        param_grid = {
            'n_estimators': [50, 100, 200],
            'max_depth': [ None, 3, 5, 10, 20],
            'min_samples_split': [2, 5, 10]
        }
        super().__init__(model, param_grid)

# Support Vector Machine

class SVMModel(BaseModel):
    def __init__(self):
        model = SVC()
        param_grid = {
            'C': [0.1, 1, 10],
            'kernel': ['linear', 'rbf', 'poly'],
            'gamma': ['scale', 'auto']
        }
        super().__init__(model, param_grid)

# Gradient Boosting (sklearn)

class GradientBoostingModel(BaseModel):
    def __init__(self):
        model = GradientBoostingClassifier()
        param_grid = {
            'n_estimators': [50, 100, 200],
            'learning_rate': [0.01, 0.05, 0.1, 0.2],
            'max_depth': [3, 5, 7, 10]
        }
        super().__init__(model, param_grid)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import ConfusionMatrixDisplay

# üìä Helper: Plot metric comparison across models
def plot_model_comparison(result_df, metric='F1 Score'):
    plt.figure(figsize=(12, 6))
    sns.barplot(
        data=result_df,
        x='Model',
        y=metric,
        hue='Phase',
        palette='Set2'
    )
    plt.title(f'{metric} Comparison Across Models (Before vs After Tuning)')
    plt.ylabel(metric)
    plt.xlabel("Model")
    plt.xticks(rotation=45)
    plt.legend(title='Phase')
    plt.tight_layout()
    plt.show()

# üìä Helper: Confusion Matrix for tuned model
def plot_confusion_matrix_custom(model_wrapper, X_test, y_test, title='Confusion Matrix'):
    y_pred = model_wrapper.predict(X_test)
    disp = ConfusionMatrixDisplay.from_predictions(y_test, y_pred)
    disp.plot(cmap='Blues')
    plt.title(title)
    plt.grid(False)
    plt.show()

# üîÅ Final Integrated Pipeline
def run_pipeline(filepath, model_classes):
    # Load and Prepare Data
    X_train, X_test, y_train, y_test = load_and_prepare_data(filepath)

    all_results = []
    tuned_models = []

    # Loop through each Model class
    for ModelClass in model_classes:
        model_name = ModelClass.__name__.replace('Model', '')
        model = ModelClass()
        print(f"\nüöÄ Running Model: {model_name}")

        # Initial training
        model.fit(X_train, y_train)
        before_tuning = model.evaluate(X_test, y_test)

        # Tuning
        try:
            best_params = model.tune(X_train, y_train)
        except Exception as e:
            best_params = f'Tuning Failed: {e}'

        after_tuning = model.evaluate(X_test, y_test)

        # Store model for post-analysis (e.g., confusion matrix)
        tuned_models.append((model_name, model))

        # Append results
        all_results.append({
            'Model': model_name,
            'Phase': "Before Tuning",
            **before_tuning
        })
        all_results.append({
            'Model': model_name,
            'Phase': "After Tuning",
            'Accuracy': after_tuning['Accuracy'],
            'Precision': after_tuning['Precision'],
            'Recall': after_tuning['Recall'],
            'F1 Score': after_tuning['F1 Score'],
            'Best Hyperparameters': best_params if isinstance(best_params, dict) else None
        })

    # Create result DataFrame
    result_df = pd.DataFrame(all_results)
    result_df = result_df[['Model', 'Phase', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Best Hyperparameters']]

    # üìä Visualization
    plot_model_comparison(result_df, metric='Accuracy')
    plot_model_comparison(result_df, metric='F1 Score')

    # üìà Confusion matrices (only after tuning)
    for model_name, model in tuned_models:
        print(f"\nüß© Confusion Matrix: {model_name} (After Tuning)")
        plot_confusion_matrix_custom(model, X_test, y_test, title=f'{model_name} - After Tuning')

    return result_df

file_path = 'https://raw.githubusercontent.com/wingsryder/Hackathon-Team26/main/Telcom-Customer-Churn.csv'  # or your uploaded/local file
result_df = run_pipeline(file_path, [
    LogisticRegressionModel,
    DecisionTreeModel,
    RandomForestModel,
    SVMModel,
    GradientBoostingModel
])

from IPython.display import display
display(result_df.sort_values(by="F1 Score", ascending=False))

